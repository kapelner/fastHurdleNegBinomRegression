% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/code.R
\name{fast_hnb_regression}
\alias{fast_hnb_regression}
\title{Fast Hurdle Negative Binomial Fit}
\usage{
fast_hnb_regression(
  Xmm,
  y,
  drop_collinear_variables = FALSE,
  lm_fit_tol = 1e-07,
  initial_phi = 10,
  num_cores = 1,
  ...
)
}
\arguments{
\item{Xmm}{The model.matrix for X (you need to create this yourself before)}

\item{y}{The count response vector}

\item{drop_collinear_variables}{Should we drop perfectly collinear variables? Default is \code{FALSE} to inform the user of the problem.}

\item{lm_fit_tol}{When \code{drop_collinear_variables = TRUE}, this is the tolerance to detect collinearity among predictors.
We use the default value from \code{base::lm.fit}'s which is 1e-7. If you fit the logistic regression and
still get p-values near 1 indicating high collinearity, we recommend making this value smaller.}

\item{initial_phi}{Value of initial starting guess for the overdispersion parameter in the count model. Default is \code{10} which is large
so the negative binomial is approximately acting as a Poisson model.}

\item{num_cores}{Number of cores to use to speed up matrix multiplication and matrix inversion (used only during inference computation). Default is 1.
Unless the number of variables, i.e. \code{ncol(Xmm)}, is large, there does not seem to be a performance gain in using multiple cores.}

\item{...}{Other arguments to be passed to \code{fastLR}. See documentation there.}
}
\value{
A list of raw results
}
\description{
Fits a hurdle negative binomial model
}
\examples{
library(MASS); data(Pima.te)
flr = fast_logistic_regression(
	 Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = as.numeric(Pima.te$type == "Yes")
)
}
